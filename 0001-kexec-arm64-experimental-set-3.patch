From 3b4da72668a70ea8ffc5483777436d643808d61f Mon Sep 17 00:00:00 2001
From: Anurup M <anurup.m@huawei.com>
Date: Thu, 7 May 2015 17:16:54 +0530
Subject: [PATCH 1/1] kexec arm64 experimental set 3

---
 arch/arm64/include/asm/smp_plat.h              |   1 +
 arch/arm64/include/asm/virt.h                  |  28 +++---
 arch/arm64/kernel/efi.c                        | 116 ++++++++++++-------------
 arch/arm64/kernel/entry.S                      |   8 ++
 arch/arm64/kernel/head.S                       |  12 +--
 arch/arm64/kernel/machine_kexec.c              |  81 ++++++++---------
 arch/arm64/kernel/process.c                    |   9 +-
 arch/arm64/kernel/relocate_kernel.S            |  21 ++++-
 arch/arm64/kernel/setup.c                      |  63 ++++++++++----
 arch/arm64/kernel/smp.c                        |  16 ++--
 arch/arm64/kvm/Kconfig                         |   1 -
 arch/arm64/kvm/hyp.S                           |  24 ++---
 arch/arm64/mm/init.c                           |  87 ++++++++++++++++++-
 drivers/firmware/efi/efi.c                     |  16 ++--
 drivers/firmware/efi/libstub/arm-stub.c        |   8 +-
 drivers/firmware/efi/libstub/efi-stub-helper.c |  10 +--
 include/linux/kexec.h                          |  20 +----
 kernel/kexec.c                                 |   1 -
 18 files changed, 306 insertions(+), 216 deletions(-)

diff --git a/arch/arm64/include/asm/smp_plat.h b/arch/arm64/include/asm/smp_plat.h
index 59e2823..c0f1fe1 100644
--- a/arch/arm64/include/asm/smp_plat.h
+++ b/arch/arm64/include/asm/smp_plat.h
@@ -39,5 +39,6 @@ static inline u32 mpidr_hash_size(void)
  */
 extern u64 __cpu_logical_map[NR_CPUS];
 #define cpu_logical_map(cpu)    __cpu_logical_map[cpu]
+void __init do_post_cpus_up_work(void);
 
 #endif /* __ASM_SMP_PLAT_H */
diff --git a/arch/arm64/include/asm/virt.h b/arch/arm64/include/asm/virt.h
index affea53..891dc53 100644
--- a/arch/arm64/include/asm/virt.h
+++ b/arch/arm64/include/asm/virt.h
@@ -18,18 +18,8 @@
 #ifndef __ASM__VIRT_H
 #define __ASM__VIRT_H
 
-/*
- * The arm64 hcall implementation uses the ISS field of the ESR_EL2 register to
- * specify the hcall type.  The exception handlers are allowed to use registers
- * x17 and x18 in their implementation.  Any routine issuing an hcall must not
- * expect these registers to be preserved.
- */
-
-/*
- * HVC_CALL_HYP - Execute a hyp routine.
- */
-
-#define HVC_CALL_HYP 3
+#define BOOT_CPU_MODE_EL1	(0xe11)
+#define BOOT_CPU_MODE_EL2	(0xe12)
 
 /*
  * HVC_GET_VECTORS - Return the value of the vbar_el2 register.
@@ -46,6 +36,12 @@
 #define HVC_SET_VECTORS 2
 
 /*
+ * HVC_CALL_HYP - Execute a hyp routine.
+ */
+
+#define HVC_CALL_HYP 3
+
+/*
  * HVC_CALL_FUNC - Execute a function at EL2.
  *
  * @x0: Physical address of the function to be executed.
@@ -64,12 +60,10 @@
  * @x0: The logical ID of the CPU.
  */
 
-//#define HVC_KVM_CPU_SHUTDOWN 4
-#define BOOT_CPU_MODE_EL1	(0xe11)
-#define BOOT_CPU_MODE_EL2	(0xe12)
+#define HVC_KVM_CPU_SHUTDOWN 4
 
 #ifndef __ASSEMBLY__
-#if 0
+
 #include <linux/stringify.h>
 #include <asm/compiler.h>
 
@@ -85,8 +79,6 @@ static inline void kvm_cpu_shutdown_2(int cpu)
 		: "+r" (cpu));
 }
 
-#endif
-
 /*
  * __boot_cpu_mode records what mode CPUs were booted in.
  * A correctly-implemented bootloader must start all CPUs in the same mode:
diff --git a/arch/arm64/kernel/efi.c b/arch/arm64/kernel/efi.c
index 1e120b25c..c9cb0fb 100644
--- a/arch/arm64/kernel/efi.c
+++ b/arch/arm64/kernel/efi.c
@@ -38,19 +38,6 @@ struct efi_memory_map memmap;
 
 static u64 efi_system_table;
 
-static pgd_t efi_pgd[PTRS_PER_PGD] __page_aligned_bss;
-
-static struct mm_struct efi_mm = {
-	.mm_rb			= RB_ROOT,
-	.pgd			= efi_pgd,
-	.mm_users		= ATOMIC_INIT(2),
-	.mm_count		= ATOMIC_INIT(1),
-	.mmap_sem		= __RWSEM_INITIALIZER(efi_mm.mmap_sem),
-	.page_table_lock	= __SPIN_LOCK_UNLOCKED(efi_mm.page_table_lock),
-	.mmlist			= LIST_HEAD_INIT(efi_mm.mmlist),
-	INIT_MM_CONTEXT(efi_mm)
-};
-
 static int uefi_debug __initdata;
 static int __init uefi_debug_setup(char *str)
 {
@@ -228,49 +215,6 @@ void __init efi_init(void)
 	reserve_regions();
 }
 
-void __init efi_virtmap_init(void)
-{
-	efi_memory_desc_t *md;
-
-	if (!efi_enabled(EFI_BOOT))
-		return;
-
-	for_each_efi_memory_desc(&memmap, md) {
-		u64 paddr, npages, size;
-		pgprot_t prot;
-
-		if (!(md->attribute & EFI_MEMORY_RUNTIME))
-			continue;
-		if (md->virt_addr == 0)
-			return;
-
-		paddr = md->phys_addr;
-		npages = md->num_pages;
-		memrange_efi_to_native(&paddr, &npages);
-		size = npages << PAGE_SHIFT;
-
-		pr_info("  EFI remap 0x%016llx => %p\n",
-			md->phys_addr, (void *)md->virt_addr);
-
-		/*
-		 * Only regions of type EFI_RUNTIME_SERVICES_CODE need to be
-		 * executable, everything else can be mapped with the XN bits
-		 * set.
-		 */
-		if (!is_normal_ram(md))
-			prot = __pgprot(PROT_DEVICE_nGnRE);
-		else if (md->type == EFI_RUNTIME_SERVICES_CODE)
-			prot = PAGE_KERNEL_EXEC;
-		else
-			prot = PAGE_KERNEL;
-
-		create_pgd_mapping(&efi_mm, paddr, md->virt_addr, size, prot);
-	}
-	set_bit(EFI_VIRTMAP, &efi.flags);
-	early_memunmap(memmap.map, memmap.map_end - memmap.map);
-//	return true;
-}
-
 /*
  * Enable the UEFI Runtime Services if all prerequisites are in place, i.e.,
  * non-early mapping of the UEFI system table and virtual mappings for all
@@ -339,6 +283,19 @@ static int __init arm64_dmi_init(void)
 }
 core_initcall(arm64_dmi_init);
 
+static pgd_t efi_pgd[PTRS_PER_PGD] __page_aligned_bss;
+
+static struct mm_struct efi_mm = {
+	.mm_rb			= RB_ROOT,
+	.pgd			= efi_pgd,
+	.mm_users		= ATOMIC_INIT(2),
+	.mm_count		= ATOMIC_INIT(1),
+	.mmap_sem		= __RWSEM_INITIALIZER(efi_mm.mmap_sem),
+	.page_table_lock	= __SPIN_LOCK_UNLOCKED(efi_mm.page_table_lock),
+	.mmlist			= LIST_HEAD_INIT(efi_mm.mmlist),
+	INIT_MM_CONTEXT(efi_mm)
+};
+
 static void efi_set_pgd(struct mm_struct *mm)
 {
 	cpu_switch_mm(mm->pgd, mm);
@@ -359,11 +316,46 @@ void efi_virtmap_unload(void)
 	preempt_enable();
 }
 
-/*
- * UpdateCapsule() depends on the system being shutdown via
- * ResetSystem().
- */
-bool efi_poweroff_required(void)
+void __init efi_virtmap_init(void)
 {
-	return efi_enabled(EFI_RUNTIME_SERVICES);
+	efi_memory_desc_t *md;
+
+	if (!efi_enabled(EFI_BOOT))
+		return;
+
+	for_each_efi_memory_desc(&memmap, md) {
+		u64 paddr, npages, size;
+		pgprot_t prot;
+
+		if (!(md->attribute & EFI_MEMORY_RUNTIME))
+			continue;
+		if (WARN(md->virt_addr == 0,
+			 "UEFI virtual mapping incomplete or missing -- no entry found for 0x%llx\n",
+			 md->phys_addr))
+			return;
+
+		paddr = md->phys_addr;
+		npages = md->num_pages;
+		memrange_efi_to_native(&paddr, &npages);
+		size = npages << PAGE_SHIFT;
+
+		pr_info("  EFI remap 0x%016llx => %p\n",
+			md->phys_addr, (void *)md->virt_addr);
+
+		/*
+		 * Only regions of type EFI_RUNTIME_SERVICES_CODE need to be
+		 * executable, everything else can be mapped with the XN bits
+		 * set.
+		 */
+		if (!is_normal_ram(md))
+			prot = __pgprot(PROT_DEVICE_nGnRE);
+		else if (md->type == EFI_RUNTIME_SERVICES_CODE)
+			prot = PAGE_KERNEL_EXEC;
+		else
+			prot = PAGE_KERNEL;
+
+		create_pgd_mapping(&efi_mm, paddr, md->virt_addr, size, prot);
+	}
+	set_bit(EFI_VIRTMAP, &efi.flags);
+	early_memunmap(memmap.map, memmap.map_end - memmap.map);
 }
diff --git a/arch/arm64/kernel/entry.S b/arch/arm64/kernel/entry.S
index c0615ec..4a8c8cc 100644
--- a/arch/arm64/kernel/entry.S
+++ b/arch/arm64/kernel/entry.S
@@ -28,6 +28,14 @@
 #include <asm/thread_info.h>
 #include <asm/unistd.h>
 
+
+.macro putc c:req
+//        mov   x21, 0x1c090000
+        mov     x21, 0x80300000
+        mov     x22, \c
+        str     x22, [x21]
+.endm
+
 /*
  * Context tracking subsystem.  Used to instrument transitions
  * between user and kernel mode.
diff --git a/arch/arm64/kernel/head.S b/arch/arm64/kernel/head.S
index 5a98702..130d45e 100644
--- a/arch/arm64/kernel/head.S
+++ b/arch/arm64/kernel/head.S
@@ -242,19 +242,11 @@ section_table:
 .macro putc c:req
 	//mov	x21, 0x1c090000
 	mov	x21, 0x80300000
-	mov	x22, \c
-	str	x22, [x21]
+	mov	x25, \c
+	str	x25, [x21]
 .endm
 
 ENTRY(stext)
-	putc	's'
-	putc	't'
-	putc	'e'
-	putc	'x'
-	putc	't'
-	putc	'\n'
-	putc	'\r'
-
 	mov	x21, x0				// x21=FDT
 	bl	el2_setup			// Drop to EL1, w20=cpu_boot_mode
 	bl	__calc_phys_offset		// x24=PHYS_OFFSET, x28=PHYS_OFFSET-PAGE_OFFSET
diff --git a/arch/arm64/kernel/machine_kexec.c b/arch/arm64/kernel/machine_kexec.c
index 142efa8..65ed885 100644
--- a/arch/arm64/kernel/machine_kexec.c
+++ b/arch/arm64/kernel/machine_kexec.c
@@ -30,7 +30,7 @@ extern unsigned long arm64_kexec_dtb_addr;
 extern unsigned long arm64_kexec_kimage_head;
 extern unsigned long arm64_kexec_kimage_start;
 
-//bool in_crash_kexec = false;
+bool in_crash_kexec = false;
 
 /**
  * kexec_is_dtb - Helper routine to check the device tree header signature.
@@ -93,15 +93,15 @@ static void _kexec_image_info(const char *func, int line,
 #if !defined(DEBUG)
 	return;
 #endif
-	pr_devel("%s:%d:\n", func, line);
-	pr_devel("  kexec image info:\n");
-	pr_devel("    type:        %d\n", image->type);
-	pr_devel("    start:       %lx\n", image->start);
-	pr_devel("    head:        %lx\n", image->head);
-	pr_devel("    nr_segments: %lu\n", image->nr_segments);
+	pr_info("%s:%d:\n", func, line);
+	pr_info("  kexec image info:\n");
+	pr_info("    type:        %d\n", image->type);
+	pr_info("    start:       %lx\n", image->start);
+	pr_info("    head:        %lx\n", image->head);
+	pr_info("    nr_segments: %lu\n", image->nr_segments);
 
 	for (i = 0; i < image->nr_segments; i++) {
-		pr_devel("      segment[%lu]: %016lx - %016lx, %lx bytes, %lu pages%s\n",
+		pr_info("      segment[%lu]: %016lx - %016lx, %lx bytes, %lu pages%s\n",
 			i,
 			image->segment[i].mem,
 			image->segment[i].mem + image->segment[i].memsz,
@@ -125,26 +125,26 @@ static void kexec_list_dump_cb(void *ctx, unsigned int flag, void *addr,
 
 	switch (flag) {
 	case IND_INDIRECTION:
-		pr_devel("  I: %pa (%p)\n", &paddr, addr);
+		pr_info("  I: %pa (%p)\n", &paddr, addr);
 		break;
 	case IND_DESTINATION:
-		pr_devel("  D: %pa (%p)\n",
+		pr_info("  D: %pa (%p)\n",
 			&paddr, addr);
 		break;
 	case IND_SOURCE:
 		if (verbosity == 2)
-			pr_devel("S");
+			pr_info("S");
 		if (verbosity == 3)
-			pr_devel("  S -> %pa (%p)\n", &pdest, dest);
+			pr_info("  S -> %pa (%p)\n", &pdest, dest);
 		if (verbosity == 4)
-			pr_devel("  S: %pa (%p) -> %pa (%p)\n", &paddr, addr,
+			pr_info("  S: %pa (%p) -> %pa (%p)\n", &paddr, addr,
 				&pdest, dest);
 		break;
 	case IND_DONE:
-		pr_devel("  DONE\n");
+		pr_info("  DONE\n");
 		break;
 	default:
-		pr_devel("  ?: %pa (%p)\n", &paddr, addr);
+		pr_info("  ?: %pa (%p)\n", &paddr, addr);
 		break;
 	}
 }
@@ -157,7 +157,7 @@ static void _kexec_list_dump(const char *func, int line,
 	return;
 #endif
 
-	pr_devel("%s:%d: kexec_list_dump:\n", func, line);
+	pr_info("%s:%d: kexec_list_dump:\n", func, line);
 
 	kexec_list_walk((void *)(unsigned long)verbosity, kimage_head,
 		kexec_list_dump_cb);
@@ -172,35 +172,34 @@ static void dump_cpus(void)
 	p = s + sprintf(s, "%s: all:       ", __func__);
 	for_each_cpu(cpu, cpu_all_mask)
 		p += sprintf(p, " %d", cpu);
-	pr_devel("%s\n", s);
+	pr_info("%s\n", s);
 
 	p = s + sprintf(s, "%s: possible:  ", __func__);
 	for_each_possible_cpu(cpu)
 		p += sprintf(p, " %d", cpu);
-	pr_devel("%s\n", s);
+	pr_info("%s\n", s);
 
 	p = s + sprintf(s, "%s: present:   ", __func__);
 	for_each_present_cpu(cpu)
 		p += sprintf(p, " %d", cpu);
-	pr_devel("%s\n", s);
+	pr_info("%s\n", s);
 
 	p = s + sprintf(s, "%s: active:    ", __func__);
 	for_each_cpu(cpu, cpu_active_mask)
 		p += sprintf(p, " %d", cpu);
-	pr_devel("%s\n", s);
+	pr_info("%s\n", s);
 
 	p = s + sprintf(s, "%s: online:    ", __func__);
 	for_each_online_cpu(cpu)
 		p += sprintf(p, " %d", cpu);
-	pr_devel("%s\n", s);
+	pr_info("%s\n", s);
 
 	p = s + sprintf(s, "%s: not online:", __func__);
 	for_each_cpu_not(cpu, cpu_online_mask)
 		p += sprintf(p, " %d", cpu);
-	pr_devel("%s\n", s);
+	pr_info("%s\n", s);
 }
 
-#if 0
 /**
  * kexec_find_dtb_seg - Helper routine to find the dtb segment.
  */
@@ -216,7 +215,6 @@ static const struct kexec_segment *kexec_find_dtb_seg(
 
 	return NULL;
 }
-#endif
 
 void machine_kexec_cleanup(struct kimage *image)
 {
@@ -230,6 +228,9 @@ void machine_kexec_cleanup(struct kimage *image)
  */
 int machine_kexec_prepare(struct kimage *image)
 {
+	const struct kexec_segment *dtb_seg = kexec_find_dtb_seg(image);
+
+	arm64_kexec_dtb_addr = dtb_seg ? dtb_seg->mem : 0;
 	arm64_kexec_kimage_start = image->start;
 
 	kexec_image_info(image);
@@ -253,7 +254,9 @@ static void kexec_list_flush(unsigned long kimage_head)
 	unsigned long *entry;
 
 	for (entry = &kimage_head, dest = NULL; ; entry++) {
-		unsigned int flag = *entry & IND_FLAGS;
+		unsigned int flag = *entry &
+			(IND_DESTINATION | IND_INDIRECTION | IND_DONE |
+			IND_SOURCE);
 		void *addr = phys_to_virt(*entry & PAGE_MASK);
 
 		switch (flag) {
@@ -295,23 +298,23 @@ void machine_kexec(struct kimage *image)
 
 	kexec_image_info(image);
 
-	pr_devel("%s:%d: control_code_page:        %p\n", __func__, __LINE__,
+	pr_info("%s:%d: control_code_page:        %p\n", __func__, __LINE__,
 		image->control_code_page);
-	pr_devel("%s:%d: reboot_code_buffer_phys:  %pa\n", __func__, __LINE__,
+	pr_info("%s:%d: reboot_code_buffer_phys:  %pa\n", __func__, __LINE__,
 		&reboot_code_buffer_phys);
-	pr_devel("%s:%d: reboot_code_buffer:       %p\n", __func__, __LINE__,
+	pr_info("%s:%d: reboot_code_buffer:       %p\n", __func__, __LINE__,
 		reboot_code_buffer);
-	pr_devel("%s:%d: relocate_new_kernel:      %p\n", __func__, __LINE__,
+	pr_info("%s:%d: relocate_new_kernel:      %p\n", __func__, __LINE__,
 		relocate_new_kernel);
-	pr_devel("%s:%d: relocate_new_kernel_size: 0x%lx(%lu) bytes\n",
+	pr_info("%s:%d: relocate_new_kernel_size: 0x%lx(%lu) bytes\n",
 		__func__, __LINE__, relocate_new_kernel_size,
 		relocate_new_kernel_size);
 
-//	pr_devel("%s:%d: kexec_dtb_addr:           %lx\n", __func__, __LINE__,
-//		arm64_kexec_dtb_addr);
-	pr_devel("%s:%d: kexec_kimage_head:        %lx\n", __func__, __LINE__,
+	pr_info("%s:%d: kexec_dtb_addr:           %lx\n", __func__, __LINE__,
+		arm64_kexec_dtb_addr);
+	pr_info("%s:%d: kexec_kimage_head:        %lx\n", __func__, __LINE__,
 		arm64_kexec_kimage_head);
-	pr_devel("%s:%d: kexec_kimage_start:       %lx\n", __func__, __LINE__,
+	pr_info("%s:%d: kexec_kimage_start:       %lx\n", __func__, __LINE__,
 		arm64_kexec_kimage_start);
 
 	kexec_list_dump(image->head, 1);
@@ -370,21 +373,21 @@ static void machine_kexec_mask_interrupts(void)
 
 void machine_crash_shutdown(struct pt_regs *regs)
 {
-/*	struct pt_regs dummy_regs;
+	struct pt_regs dummy_regs;
 	int cpu;
-*/
+
 	local_irq_disable();
-//	in_crash_kexec = true;
+	in_crash_kexec = true;
 
 	/*
 	 * clear and initialize the per-cpu info. This is necessary
 	 * because, otherwise, slots for offline cpus would not be
 	 * filled up. See smp_send_stop().
 	 */
-/*	memset(&dummy_regs, 0, sizeof(dummy_regs));
+	memset(&dummy_regs, 0, sizeof(dummy_regs));
 	for_each_possible_cpu(cpu)
 		crash_save_cpu(&dummy_regs, cpu);
-*/
+
 	/* shutdown non-boot cpus */
 	smp_send_stop();
 
diff --git a/arch/arm64/kernel/process.c b/arch/arm64/kernel/process.c
index 49282fd..b27869a 100644
--- a/arch/arm64/kernel/process.c
+++ b/arch/arm64/kernel/process.c
@@ -63,21 +63,20 @@ EXPORT_SYMBOL(__stack_chk_guard);
 void soft_restart(unsigned long addr)
 {
 	setup_mm_for_reboot();
-#if 0
 #ifdef CONFIG_KEXEC
-//	printk("------------- Value of in_crash_kexec=%d is_hyp_mode_available=%d\n",
+	printk("------------- Value of in_crash_kexec=%d is_hyp_mode_available=%d\n",
 				in_crash_kexec, is_hyp_mode_available());
 #endif
-#endif
+
 	/* TODO: Remove this conditional when KVM can support CPU restart. */
 	if (IS_ENABLED(CONFIG_KVM))
 		cpu_soft_restart(virt_to_phys(cpu_reset), 0, addr);
 	else
 		cpu_soft_restart(virt_to_phys(cpu_reset),
-#if 0
 #ifdef CONFIG_KEXEC
+//#if 0
 		!in_crash_kexec &&
-#endif
+//#endif
 #endif
 		is_hyp_mode_available(), addr);
 
diff --git a/arch/arm64/kernel/relocate_kernel.S b/arch/arm64/kernel/relocate_kernel.S
index 991df4b..7f6b4c6 100644
--- a/arch/arm64/kernel/relocate_kernel.S
+++ b/arch/arm64/kernel/relocate_kernel.S
@@ -8,14 +8,26 @@
  * published by the Free Software Foundation.
  */
 
-#include <linux/kexec.h>
-
 #include <asm/assembler.h>
 #include <asm/kexec.h>
 #include <asm/memory.h>
 #include <asm/page.h>
 #include <asm/proc-macros.S>
 
+/* The list entry flags. */
+
+#define IND_DESTINATION_BIT 0
+#define IND_INDIRECTION_BIT 1
+#define IND_DONE_BIT        2
+#define IND_SOURCE_BIT      3
+
+.macro putc c:req
+        //mov   x21, 0x1c090000
+        mov     x21, 0x80300000
+        mov     x22, \c
+        str     x22, [x21]
+.endm
+
 /*
  * relocate_new_kernel - Put a 2nd stage kernel image in place and boot it.
  *
@@ -130,8 +142,9 @@ arm64_kexec_kimage_start:
 	.quad	0x0
 
 /*
- * arm64_kexec_dtb_addr - Physical address of device tree.
-*/
+ * arm64_kexec_dtb_addr - Physical address of a device tree.
+ */
+.globl arm64_kexec_dtb_addr
 arm64_kexec_dtb_addr:
 	.quad	0x0
 
diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c
index d0348a4..66a2090 100644
--- a/arch/arm64/kernel/setup.c
+++ b/arch/arm64/kernel/setup.c
@@ -41,16 +41,17 @@
 #include <linux/fs.h>
 #include <linux/proc_fs.h>
 #include <linux/memblock.h>
+#include <linux/of_iommu.h>
 #include <linux/of_fdt.h>
 #include <linux/of_platform.h>
 #include <linux/efi.h>
+#include <asm/cputable.h>
 #include <linux/personality.h>
 
 #include <asm/fixmap.h>
 #include <asm/cpu.h>
 #include <asm/cputype.h>
 #include <asm/elf.h>
-#include <asm/cputable.h>
 #include <asm/cpufeature.h>
 #include <asm/cpu_ops.h>
 #include <asm/sections.h>
@@ -62,7 +63,6 @@
 #include <asm/memblock.h>
 #include <asm/psci.h>
 #include <asm/efi.h>
-#include <asm/acpi.h>
 #include <asm/virt.h>
 
 unsigned int processor_id;
@@ -121,6 +121,11 @@ void __init early_print(const char *str, ...)
 	printk("%s", buf);
 }
 
+/*
+ * The recorded values of x0 .. x3 upon kernel entry.
+ */
+u64 __cacheline_aligned boot_args[4];
+
 void __init smp_setup_processor_id(void)
 {
 	u64 mpidr = read_cpuid_mpidr() & MPIDR_HWID_BITMASK;
@@ -209,6 +214,30 @@ static void __init smp_build_mpidr_hash(void)
 }
 #endif
 
+static void __init hyp_mode_check(void)
+{
+	if (is_hyp_mode_available())
+		pr_info("CPU: All CPU(s) started at EL2\n");
+	else if (is_hyp_mode_mismatched())
+		WARN_TAINT(1, TAINT_CPU_OUT_OF_SPEC,
+			   "CPU: CPUs started in inconsistent modes");
+	else
+		pr_info("CPU: All CPU(s) started at EL1\n");
+}
+
+void __init do_post_cpus_up_work(void)
+{
+	hyp_mode_check();
+	apply_alternatives_all();
+}
+
+#ifdef CONFIG_UP_LATE_INIT
+void __init up_late_init(void)
+{
+	do_post_cpus_up_work();
+}
+#endif /* CONFIG_UP_LATE_INIT */
+
 static void __init setup_processor(void)
 {
 	struct cpu_info *cpu_info;
@@ -343,7 +372,7 @@ static inline unsigned long long get_total_mem(void)
  */
 static void __init reserve_crashkernel(void)
 {
-	unsigned long long crash_size, crash_base;
+	unsigned long long crash_size = 0, crash_base = 0;
 	int ret;
 
 	/* use ULONG_MAX since we don't know system memory size here. */
@@ -463,9 +492,9 @@ void __init setup_arch(char **cmdline_p)
 #endif
 
 	arm64_memblock_init();
-
-	/* Parse the ACPI tables for possible boot-time configuration */
-	acpi_boot_table_init();
+	
+        /* Parse the ACPI tables for possible boot-time configuration */
+        acpi_boot_table_init();
 
 	paging_init();
 	request_standard_resources();
@@ -474,20 +503,21 @@ void __init setup_arch(char **cmdline_p)
 	/* kexec-tool will detect the region with /proc/iomem */
 	insert_resource(&iomem_resource, &crashk_res);
 #endif
+
 	efi_virtmap_init();
-	early_ioremap_reset();
 
-	if (acpi_disabled) {
-		unflatten_device_tree();
-		psci_dt_init();
-		cpu_read_bootcpu_ops();
+	early_ioremap_reset();
+        if (acpi_disabled) {
+               unflatten_device_tree();
+               psci_dt_init();
+               cpu_read_bootcpu_ops();
 #ifdef CONFIG_SMP
-		of_smp_init_cpus();
+               of_smp_init_cpus();
 #endif
-	} else {
-		psci_acpi_init();
-		acpi_smp_init_cpus();
-	}
+       } else {
+               psci_acpi_init();
+               acpi_smp_init_cpus();
+       }
 
 #ifdef CONFIG_SMP
 	smp_build_mpidr_hash();
@@ -504,6 +534,7 @@ void __init setup_arch(char **cmdline_p)
 
 static int __init arm64_device_init(void)
 {
+	of_iommu_init();
 	of_platform_populate(NULL, of_default_bus_match_table, NULL, NULL);
 	return 0;
 }
diff --git a/arch/arm64/kernel/smp.c b/arch/arm64/kernel/smp.c
index 2fb8200..e8f50dd 100644
--- a/arch/arm64/kernel/smp.c
+++ b/arch/arm64/kernel/smp.c
@@ -545,8 +545,8 @@ static DEFINE_RAW_SPINLOCK(stop_lock);
 /*
  * ipi_cpu_stop - handle IPI from smp_send_stop()
  */
-//static void ipi_cpu_stop(unsigned int cpu, struct pt_regs *regs)
-static void ipi_cpu_stop(unsigned int cpu)
+//static void ipi_cpu_stop(unsigned int cpu)
+static void ipi_cpu_stop(unsigned int cpu, struct pt_regs *regs)
 {
 	if (system_state == SYSTEM_BOOTING ||
 	    system_state == SYSTEM_RUNNING) {
@@ -559,12 +559,14 @@ static void ipi_cpu_stop(unsigned int cpu)
 	set_cpu_online(cpu, false);
 
 	local_irq_disable();
-#if 0
 #ifdef CONFIG_KEXEC
-	if (in_crash_kexec)
+//#if 0
+	if (in_crash_kexec) {
 		crash_save_cpu(regs, cpu);
+		flush_cache_all();
+	}
+//#endif
 #endif /* CONFIG_KEXEC */
-#endif
 	while (1)
 		cpu_relax();
 }
@@ -601,8 +603,8 @@ void handle_IPI(int ipinr, struct pt_regs *regs)
 
 	case IPI_CPU_STOP:
 		irq_enter();
-//		ipi_cpu_stop(cpu, regs);
-		ipi_cpu_stop(cpu);
+		ipi_cpu_stop(cpu, regs);
+		//ipi_cpu_stop(cpu);
 		irq_exit();
 		break;
 
diff --git a/arch/arm64/kvm/Kconfig b/arch/arm64/kvm/Kconfig
index 5079a30..8ba85e9 100644
--- a/arch/arm64/kvm/Kconfig
+++ b/arch/arm64/kvm/Kconfig
@@ -18,7 +18,6 @@ if VIRTUALIZATION
 
 config KVM
 	bool "Kernel-based Virtual Machine (KVM) support"
-	depends on !KEXEC
 	select MMU_NOTIFIER
 	select PREEMPT_NOTIFIERS
 	select ANON_INODES
diff --git a/arch/arm64/kvm/hyp.S b/arch/arm64/kvm/hyp.S
index bb4a7ec..271c9c9 100644
--- a/arch/arm64/kvm/hyp.S
+++ b/arch/arm64/kvm/hyp.S
@@ -1145,10 +1145,10 @@ el1_sync:					// Guest trapped into EL2
 	push	x2, x3
 
 	mrs	x1, esr_el2
-	lsr	x2, x1, #ESR_ELx_EC_SHIFT
-	and	x0, x1, #ESR_ELx_ISS_MASK
+	and	x0, x1, #ESR_EL2_ISS
+	lsr	x2, x1, #ESR_EL2_EC_SHIFT
 
-	cmp	x2, #ESR_ELx_EC_HVC64
+	cmp	x2, #ESR_EL2_EC_HVC64
 	b.ne	el1_trap
 
 	mrs	x3, vttbr_el2			// If vttbr is valid, the 64bit guest
@@ -1164,7 +1164,7 @@ el1_sync:					// Guest trapped into EL2
 	mrs	x0, vbar_el2
 	b	2f
 
-	b.ne	1f
+1:	/* Default to HVC_CALL_HYP. */
 
 	push	lr, xzr
 
@@ -1179,30 +1179,20 @@ el1_sync:					// Guest trapped into EL2
 	blr	lr
 
 	pop	lr, xzr
-	b	2f
-
-1:	cmp	x10, #HVC_KVM_CPU_SHUTDOWN
-	b.ne	3f
-
-	// TODO.
-
-	b	2f
-
 2:	eret
-3:	br	xzr				// panic
 
 el1_trap:
 	/*
 	 * x1: ESR
 	 * x2: ESR_EC
 	 */
-	cmp	x2, #ESR_ELx_EC_DABT_LOW
-	mov	x0, #ESR_ELx_EC_IABT_LOW
+	cmp	x2, #ESR_EL2_EC_DABT
+	mov	x0, #ESR_EL2_EC_IABT
 	ccmp	x2, x0, #4, ne
 	b.ne	1f		// Not an abort we care about
 
 	/* This is an abort. Check for permission fault */
-	and	x2, x1, #ESR_ELx_FSC_TYPE
+	and	x2, x1, #ESR_EL2_FSC_TYPE
 	cmp	x2, #FSC_PERM
 	b.ne	1f		// Not a permission fault
 
diff --git a/arch/arm64/mm/init.c b/arch/arm64/mm/init.c
index e0e0cc3..8ca832d 100644
--- a/arch/arm64/mm/init.c
+++ b/arch/arm64/mm/init.c
@@ -34,6 +34,8 @@
 #include <linux/dma-contiguous.h>
 #include <linux/efi.h>
 #include <linux/swiotlb.h>
+#include <linux/kexec.h>
+#include <linux/crash_dump.h>
 
 #include <asm/fixmap.h>
 #include <asm/sections.h>
@@ -65,6 +67,84 @@ static int __init early_initrd(char *p)
 early_param("initrd", early_initrd);
 #endif
 
+#if 0
++#ifdef CONFIG_KEXEC
++/*
++ * reserve_crashkernel() - reserves memory for crash kernel
++ *
++ * This function reserves memory area given in "crashkernel=" kernel command
++ * line parameter. The memory reserved is used by a dump capture kernel when
++ * primary kernel is crashing.
++ */
++static void __init reserve_crashkernel(phys_addr_t limit)
++{
++	unsigned long long crash_size = 0, crash_base = 0;
++	int ret;
++
++	ret = parse_crashkernel(boot_command_line, limit,
++				&crash_size, &crash_base);
++	if (ret)
++		return;
++
++	if (crash_base == 0) {
++		crash_base = memblock_alloc(crash_size, 1 << 20);
++		if (crash_base == 0) {
++			pr_warn("crashkernel allocation failed (size:%llx)\n",
++				crash_size);
++			return;
++		}
++	} else {
++		/* User specifies base address explicitly. Sanity check */
++		if (!memblock_is_region_memory(crash_base, crash_size) ||
++			memblock_is_region_reserved(crash_base, crash_size)) {
++			pr_warn("crashkernel= has wrong address or size\n");
++			return;
++		}
++
++		if (memblock_reserve(crash_base, crash_size)) {
++			pr_warn("crashkernel reservation failed - out of memory\n");
++			return;
++		}
++	}
++
++	pr_info("Reserving %lldMB of memory at %lldMB for crashkernel\n",
++		crash_size >> 20, crash_base >> 20);
++
++	crashk_res.start = crash_base;
++	crashk_res.end = crash_base + crash_size - 1;
++}
++#endif /* CONFIG_KEXEC */
++
++#ifdef CONFIG_CRASH_DUMP
++/*
++ * reserve_elfcorehdr() - reserves memory for elf core header
++ *
++ * This function reserves memory area given in "elfcorehdr=" kernel command
++ * line parameter. The memory reserved is used by a dump capture kernel to
++ * identify the memory used by primary kernel.
++ */
++static void __init reserve_elfcorehdr(void)
++{
++	if (!elfcorehdr_size)
++		return;
++
++	if (memblock_is_region_reserved(elfcorehdr_addr, elfcorehdr_size)) {
++		pr_warn("elfcorehdr reservation failed - memory is in use (0x%llx)\n",
++			elfcorehdr_addr);
++		return;
++	}
++
++	if (memblock_reserve(elfcorehdr_addr, elfcorehdr_size)) {
++		pr_warn("elfcorehdr reservation failed - out of memory\n");
++		return;
++	}
++
++	pr_info("Reserving %lldKB of memory at %lldMB for elfcorehdr\n",
++		elfcorehdr_size >> 10, elfcorehdr_addr >> 20);
++}
++#endif /* CONFIG_CRASH_DUMP */
+#endif
+
 /*
  * Return the maximum physical address for ZONE_DMA (DMA_BIT_MASK(32)). It
  * currently assumes that for memory starting above 4G, 32-bit devices will
@@ -358,8 +438,13 @@ static int keep_initrd;
 
 void free_initrd_mem(unsigned long start, unsigned long end)
 {
-	if (!keep_initrd)
+	if (!keep_initrd) {
+		if (start == initrd_start)
+			start = round_down(start, PAGE_SIZE);
+		if (end == initrd_end)
+			end = round_up(end, PAGE_SIZE);
 		free_reserved_area((void *)start, (void *)end, 0, "initrd");
+	}
 }
 
 static int __init keepinitrd_setup(char *__unused)
diff --git a/drivers/firmware/efi/efi.c b/drivers/firmware/efi/efi.c
index 31a1b85..b7ba9d8 100644
--- a/drivers/firmware/efi/efi.c
+++ b/drivers/firmware/efi/efi.c
@@ -115,24 +115,15 @@ EFI_ATTR_SHOW(fw_vendor);
 EFI_ATTR_SHOW(runtime);
 EFI_ATTR_SHOW(config_table);
 
-static ssize_t fw_platform_size_show(struct kobject *kobj,
-				     struct kobj_attribute *attr, char *buf)
-{
-	return sprintf(buf, "%d\n", efi_enabled(EFI_64BIT) ? 64 : 32);
-}
-
 static struct kobj_attribute efi_attr_fw_vendor = __ATTR_RO(fw_vendor);
 static struct kobj_attribute efi_attr_runtime = __ATTR_RO(runtime);
 static struct kobj_attribute efi_attr_config_table = __ATTR_RO(config_table);
-static struct kobj_attribute efi_attr_fw_platform_size =
-	__ATTR_RO(fw_platform_size);
 
 static struct attribute *efi_subsys_attrs[] = {
 	&efi_attr_systab.attr,
 	&efi_attr_fw_vendor.attr,
 	&efi_attr_runtime.attr,
 	&efi_attr_config_table.attr,
-	&efi_attr_fw_platform_size.attr,
 	NULL,
 };
 
@@ -285,7 +276,11 @@ static __init int match_config_table(efi_guid_t *guid,
 	int i;
 
 	if (table_types) {
+		efi_guid_unparse(guid, str);
+
 		for (i = 0; efi_guidcmp(table_types[i].guid, NULL_GUID); i++) {
+			efi_guid_unparse(&table_types[i].guid, str);
+
 			if (!efi_guidcmp(*guid, table_types[i].guid)) {
 				*(table_types[i].ptr) = table;
 				pr_cont(" %s=0x%lx ",
@@ -416,7 +411,8 @@ static int __init fdt_find_uefi_params(unsigned long node, const char *uname,
 	u64 val;
 	int i, len;
 
-	if (depth != 1 || strcmp(uname, "chosen") != 0)
+	if (depth != 1 ||
+	    (strcmp(uname, "chosen") != 0 && strcmp(uname, "chosen@0") != 0))
 		return 0;
 
 	for (i = 0; i < ARRAY_SIZE(dt_params); i++) {
diff --git a/drivers/firmware/efi/libstub/arm-stub.c b/drivers/firmware/efi/libstub/arm-stub.c
index dcae482..e2432b3 100644
--- a/drivers/firmware/efi/libstub/arm-stub.c
+++ b/drivers/firmware/efi/libstub/arm-stub.c
@@ -17,10 +17,10 @@
 
 #include "efistub.h"
 
-static int efi_secureboot_enabled(efi_system_table_t *sys_table_arg)
+static int __init efi_secureboot_enabled(efi_system_table_t *sys_table_arg)
 {
-	static efi_guid_t const var_guid = EFI_GLOBAL_VARIABLE_GUID;
-	static efi_char16_t const var_name[] = {
+	static efi_guid_t const var_guid __initconst = EFI_GLOBAL_VARIABLE_GUID;
+	static efi_char16_t const var_name[] __initconst = {
 		'S', 'e', 'c', 'u', 'r', 'e', 'B', 'o', 'o', 't', 0 };
 
 	efi_get_variable_t *f_getvar = sys_table_arg->runtime->get_variable;
@@ -164,7 +164,7 @@ efi_status_t handle_kernel_image(efi_system_table_t *sys_table,
  * for both archictectures, with the arch-specific code provided in the
  * handle_kernel_image() function.
  */
-unsigned long efi_entry(void *handle, efi_system_table_t *sys_table,
+unsigned long __init efi_entry(void *handle, efi_system_table_t *sys_table,
 			       unsigned long *image_addr)
 {
 	efi_loaded_image_t *image;
diff --git a/drivers/firmware/efi/libstub/efi-stub-helper.c b/drivers/firmware/efi/libstub/efi-stub-helper.c
index f07d4a6..e766df6 100644
--- a/drivers/firmware/efi/libstub/efi-stub-helper.c
+++ b/drivers/firmware/efi/libstub/efi-stub-helper.c
@@ -110,7 +110,7 @@ fail:
 }
 
 
-unsigned long get_dram_base(efi_system_table_t *sys_table_arg)
+unsigned long __init get_dram_base(efi_system_table_t *sys_table_arg)
 {
 	efi_status_t status;
 	unsigned long map_size;
@@ -179,12 +179,12 @@ again:
 		start = desc->phys_addr;
 		end = start + desc->num_pages * (1UL << EFI_PAGE_SHIFT);
 
-		if (end > max)
-			end = max;
-
-		if ((start + size) > end)
+		if ((start + size) > end || (start + size) > max)
 			continue;
 
+		if (end - size > max)
+			end = max;
+
 		if (round_down(end - size, align) < start)
 			continue;
 
diff --git a/include/linux/kexec.h b/include/linux/kexec.h
index b23412c..9d957b7 100644
--- a/include/linux/kexec.h
+++ b/include/linux/kexec.h
@@ -1,19 +1,6 @@
 #ifndef LINUX_KEXEC_H
 #define LINUX_KEXEC_H
 
-#define IND_DESTINATION_BIT 0
-#define IND_INDIRECTION_BIT 1
-#define IND_DONE_BIT        2
-#define IND_SOURCE_BIT      3
-
-#define IND_DESTINATION  (1 << IND_DESTINATION_BIT)
-#define IND_INDIRECTION  (1 << IND_INDIRECTION_BIT)
-#define IND_DONE         (1 << IND_DONE_BIT)
-#define IND_SOURCE       (1 << IND_SOURCE_BIT)
-#define IND_FLAGS (IND_DESTINATION | IND_INDIRECTION | IND_DONE | IND_SOURCE)
-
-#if !defined(__ASSEMBLY__)
-
 #include <uapi/linux/kexec.h>
 
 #ifdef CONFIG_KEXEC
@@ -77,6 +64,10 @@
  */
 
 typedef unsigned long kimage_entry_t;
+#define IND_DESTINATION  0x1
+#define IND_INDIRECTION  0x2
+#define IND_DONE         0x4
+#define IND_SOURCE       0x8
 
 struct kexec_segment {
 	/*
@@ -322,7 +313,4 @@ struct task_struct;
 static inline void crash_kexec(struct pt_regs *regs) { }
 static inline int kexec_should_crash(struct task_struct *p) { return 0; }
 #endif /* CONFIG_KEXEC */
-
-#endif /* !defined(__ASSEBMLY__) */
-
 #endif /* LINUX_KEXEC_H */
diff --git a/kernel/kexec.c b/kernel/kexec.c
index 0364fb5..df0d226 100644
--- a/kernel/kexec.c
+++ b/kernel/kexec.c
@@ -1596,7 +1596,6 @@ void crash_save_cpu(struct pt_regs *regs, int cpu)
 
 	if ((cpu < 0) || (cpu >= nr_cpu_ids))
 		return;
-
 	/* Using ELF notes here is opportunistic.
 	 * I need a well defined structure format
 	 * for the data I pass, and I need tags
-- 
1.9.1

